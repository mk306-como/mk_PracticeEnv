{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice OBDA for Parquet files \n",
    "\n",
    "---\n",
    "This Jupiter Notebook creates a parquet data base, creates and ontology and then constructs an OBDA map to SPARQL query the Parquet database\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Parquet schema and instances and write parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import Parquet libraries\n",
    "# import pandas as pd\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# # Define a schema and print\n",
    "# schema = pa.schema([\n",
    "#     ('Name', pa.string()),\n",
    "#     ('Age', pa.int32()),\n",
    "#     ('City', pa.string())\n",
    "# ])\n",
    "# # print(schema)\n",
    "\n",
    "# # Sample data\n",
    "# data = {\n",
    "#     'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "#     'Age': [25, 30, 35,40],\n",
    "#     'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "# }\n",
    "\n",
    "# # Create a Pandas DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Convert the Pandas DataFrame to a PyArrow Table\n",
    "# table = pa.Table.from_pandas(df, schema=schema)\n",
    "\n",
    "\n",
    "# # Write the PyArrow Table to a Parquet file\n",
    "# parquet_file = 'my_Parquet-file.parquet'\n",
    "# pq.write_table(table, parquet_file)\n",
    "\n",
    "# # Read the Parquet file back into a PyArrow Table\n",
    "# table_read = pq.read_table(parquet_file)\n",
    "\n",
    "# # Convert the PyArrow Table back to a Pandas DataFrame\n",
    "# df_read = table_read.to_pandas()\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(\"Data read from Parquet file with schema:\")\n",
    "# print(df_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Ontology from Parquet schema and perform a SPARQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from Parquet file:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    David   40      Houston\n",
      "\n",
      "Ontology saved to parquet_ontology.owl\n",
      "\n",
      "SPARQL query results (Records with Age > 36):\n",
      "Record: http://example.org/parquet_ontology.owl#Record_0, Name: Alice, Age: 25, City: New York\n",
      "Record: http://example.org/parquet_ontology.owl#Record_1, Name: Bob, Age: 30, City: Los Angeles\n",
      "Record: http://example.org/parquet_ontology.owl#Record_2, Name: Charlie, Age: 35, City: Chicago\n",
      "Record: http://example.org/parquet_ontology.owl#Record_3, Name: David, Age: 40, City: Houston\n"
     ]
    }
   ],
   "source": [
    "# === Step 1: Create and read the Parquet file ===\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define the schema for the Parquet file\n",
    "schema = pa.schema([\n",
    "    ('Name', pa.string()),\n",
    "    ('Age', pa.int32()),\n",
    "    ('City', pa.string())\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a PyArrow Table and write to a Parquet file\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "parquet_file = 'my_Parquet-file.parquet'\n",
    "pq.write_table(table, parquet_file)\n",
    "\n",
    "# Read the Parquet file back into a Pandas DataFrame\n",
    "table_read = pq.read_table(parquet_file)\n",
    "df_read = table_read.to_pandas()\n",
    "\n",
    "print(\"Data read from Parquet file:\")\n",
    "print(df_read)\n",
    "\n",
    "# === Step 2: Create an ontology based solely on the Parquet file ===\n",
    "from owlready2 import get_ontology, Thing, DataProperty, FunctionalProperty\n",
    "\n",
    "# Create an ontology (the base IRI can be any URI you choose)\n",
    "onto = get_ontology(\"http://example.org/parquet_ontology.owl#\")\n",
    "\n",
    "with onto:\n",
    "    # Define a generic class for the records; here we call it \"Record\"\n",
    "    class Record(Thing):\n",
    "        pass\n",
    "\n",
    "    # Define properties for each column in the DataFrame\n",
    "    class hasName(DataProperty, FunctionalProperty):\n",
    "        domain = [Record]\n",
    "        range = [str]\n",
    "\n",
    "    class hasAge(DataProperty, FunctionalProperty):\n",
    "        domain = [Record]\n",
    "        range = [int]\n",
    "\n",
    "    class hasCity(DataProperty, FunctionalProperty):\n",
    "        domain = [Record]\n",
    "        range = [str]\n",
    "\n",
    "    # Create individuals (instances of Record) from each row in the DataFrame\n",
    "    for index, row in df_read.iterrows():\n",
    "        # Use a unique identifier for each individual (e.g., \"Record_0\", \"Record_1\", etc.)\n",
    "        individual = Record(f\"Record_{index}\")\n",
    "        individual.hasName = row['Name']\n",
    "        individual.hasAge = row['Age']\n",
    "        individual.hasCity = row['City']\n",
    "\n",
    "# Save the ontology to an OWL file (RDF/XML format)\n",
    "ontology_file = \"parquet_ontology.owl\"\n",
    "onto.save(file=ontology_file, format=\"rdfxml\")\n",
    "print(f\"\\nOntology saved to {ontology_file}\")\n",
    "\n",
    "# === Step 3: Load the ontology with rdflib and run a SPARQL query ===\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "# Load the saved ontology file\n",
    "g = Graph()\n",
    "g.parse(ontology_file)\n",
    "\n",
    "# Define a namespace for the ontology\n",
    "EX = Namespace(\"http://example.org/parquet_ontology.owl#\")\n",
    "g.bind(\"ex\", EX)\n",
    "\n",
    "# SPARQL query to mimic the DataFrame filter: select records with Age > 36\n",
    "sparql_query = \"\"\"\n",
    "PREFIX ex: <http://example.org/parquet_ontology.owl#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "SELECT ?record ?name ?age ?city\n",
    "WHERE {\n",
    "    ?record a ex:Record .\n",
    "    ?record ex:hasName ?name .\n",
    "    ?record ex:hasAge ?age .\n",
    "    ?record ex:hasCity ?city .\n",
    "    FILTER(xsd:integer(?age) > 20)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "results = g.query(sparql_query)\n",
    "\n",
    "print(\"\\nSPARQL query results (Records with Age > 36):\")\n",
    "for row in results:\n",
    "    print(f\"Record: {row.record}, Name: {row.name}, Age: {row.age}, City: {row.city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from owlready2 import *\n",
    "# from rdflib import Graph\n",
    "\n",
    "# # Step 1: Create the ontology using owlready2\n",
    "# def create_ontology_with_owlready2():\n",
    "#     # Create a new ontology\n",
    "#     onto = get_ontology(\"http://example.org/ontology#\")\n",
    "\n",
    "#     # Define the Person class\n",
    "#     # class Person(Thing):\n",
    "#         namespace = onto\n",
    "\n",
    "#     # Define properties\n",
    "#     class hasName(DataProperty, FunctionalProperty):\n",
    "#         namespace = onto\n",
    "#         domain = [Person]\n",
    "#         range = [str]\n",
    "\n",
    "#     class hasAge(DataProperty, FunctionalProperty):\n",
    "#         namespace = onto\n",
    "#         domain = [Person]\n",
    "#         range = [int]\n",
    "\n",
    "#     class hasCity(DataProperty, FunctionalProperty):\n",
    "#         namespace = onto\n",
    "#         domain = [Person]\n",
    "#         range = [str]\n",
    "\n",
    "#     # Sample data\n",
    "#     data = {\n",
    "#         'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "#         'Age': [25, 30, 35, 40],\n",
    "#         'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "#     }\n",
    "\n",
    "#     # Add individuals to the ontology\n",
    "#     for i in range(len(data['Name'])):\n",
    "#         person = Person(name=data['Name'][i])  # Create an individual\n",
    "#         person.hasName = data['Name'][i]       # Assign hasName property\n",
    "#         person.hasAge = data['Age'][i]         # Assign hasAge property\n",
    "#         person.hasCity = data['City'][i]       # Assign hasCity property\n",
    "\n",
    "#     # Save the ontology to an OWL file\n",
    "#     onto.save(file=\"my_Parquet_ontology.owl\", format=\"rdfxml\")\n",
    "#     print(\"Ontology created and saved to 'my_Parquet_ontology.owl'\")\n",
    "\n",
    "# # Step 2: Query the ontology using rdflib\n",
    "# def query_ontology_with_rdflib():\n",
    "#     # Load the ontology into an RDF graph\n",
    "#     g = Graph()\n",
    "#     g.parse(\"my_Parquet_ontology.owl\", format=\"xml\")\n",
    "\n",
    "#     # Define a SPARQL query to retrieve all persons and their details\n",
    "#     sparql_query = \"\"\"\n",
    "#     PREFIX ex: <http://example.org/ontology#>\n",
    "#     SELECT ?person ?name ?age ?city\n",
    "#     WHERE {\n",
    "#         ?person a ex:Person .\n",
    "#         ?person ex:hasName ?name .\n",
    "#         ?person ex:hasAge ?age .\n",
    "#         ?person ex:hasCity ?city .\n",
    "#     }\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Execute the SPARQL query\n",
    "#     results = g.query(sparql_query)\n",
    "\n",
    "#     # Print the results\n",
    "#     print(\"\\nResults from SPARQL query:\")\n",
    "#     for row in results:\n",
    "#         print(f\"Person: {row.person}, Name: {row.name}, Age: {row.age}, City: {row.city}\")\n",
    "\n",
    "# # Main program\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Step 1: Create the ontology\n",
    "#     create_ontology_with_owlready2()\n",
    "\n",
    "#     # Step 2: Query the ontology\n",
    "#     query_ontology_with_rdflib()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
