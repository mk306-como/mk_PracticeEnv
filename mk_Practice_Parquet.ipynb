{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from Parquet file with schema:\n",
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    David   40      Houston\n",
      "Final DataFrame:\n",
      "    Name  Age     City  IsAdult\n",
      "3  David   40  Houston     True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define a schema and print\n",
    "schema = pa.schema([\n",
    "    ('Name', pa.string()),\n",
    "    ('Age', pa.int32()),\n",
    "    ('City', pa.string())\n",
    "])\n",
    "# print(schema)\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35,40],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the Pandas DataFrame to a PyArrow Table\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "\n",
    "# Write the PyArrow Table to a Parquet file\n",
    "parquet_file = 'example_with_schema.parquet'\n",
    "pq.write_table(table, parquet_file)\n",
    "\n",
    "# Read the Parquet file back into a PyArrow Table\n",
    "table_read = pq.read_table(parquet_file)\n",
    "\n",
    "# Convert the PyArrow Table back to a Pandas DataFrame\n",
    "df_read = table_read.to_pandas()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Data read from Parquet file with schema:\")\n",
    "print(df_read)\n",
    "\n",
    "# # viewing data in a DataFrame\n",
    "# print(df_read.head(2))  # First 2 rows\n",
    "# print(df_read.tail(2))  # Last 2 rows\n",
    "# print(df_read.shape)    # (rows, columns)\n",
    "# print(df_read.columns)  # Column names\n",
    "\n",
    "# # Filter rows where Age is greater than 30\n",
    "# filtered_df = df_read[df_read['Age'] > 36]\n",
    "# print(filtered_df)\n",
    "\n",
    "# # Add a new column 'IsAdult' (True if Age >= 18)\n",
    "# df_read['IsAdult'] = df_read['Age'] >= 32\n",
    "# print(df_read)\n",
    "\n",
    "# # Increment everyone's age by 1\n",
    "# df_read['Age'] = df_read['Age'] + 1\n",
    "# print(df_read)\n",
    "\n",
    "# # Drop the 'City' column\n",
    "# df_read = df_read.drop(columns=['City'])\n",
    "# print(df_read)\n",
    "\n",
    "# # Sort by Age in descending order\n",
    "# sorted_df = df_read.sort_values(by='Age', ascending=False)\n",
    "# print(sorted_df)\n",
    "\n",
    "# # Group by 'City' and calculate the average age\n",
    "# grouped_df = df_read.groupby('City')['Age'].mean().reset_index()\n",
    "# print(grouped_df)\n",
    "\n",
    "# # Rename 'Name' to 'FullName' and 'Age' to 'Years'\n",
    "# df_read = df_read.rename(columns={'Name': 'FullName', 'Age': 'Years'})\n",
    "# print(df_read)\n",
    "\n",
    "### mk: i do not understand the limce below\n",
    "# # Drop rows with missing values\n",
    "# df_read = df_read.dropna()\n",
    "\n",
    "# # Fill missing values in 'Age' with the mean\n",
    "# df_read['Age'] = df_read['Age'].fillna(df_read['Age'].mean())\n",
    "# print(df_read)\n",
    "\n",
    "# # Convert all names to uppercase\n",
    "# df_read['Name'] = df_read['Name'].apply(lambda x: x.upper())\n",
    "# print(df_read)\n",
    "\n",
    "# # Create a second DataFrame\n",
    "# data2 = {\n",
    "#     'Name': ['Alice', 'Bob', 'Eve'],\n",
    "#     'Salary': [50000, 60000, 70000]\n",
    "# }\n",
    "# df2 = pd.DataFrame(data2)\n",
    "# # Merge with the original DataFrame on 'Name'\n",
    "# merged_df = pd.merge(df_read, df2, on='Name', how='left')\n",
    "# print(merged_df)\n",
    "\n",
    "# # Fill missing values in 'Age' with the mean\n",
    "# merged_df['Salary'] = merged_df['Salary'].fillna(merged_df['Salary'].mean())\n",
    "# print(merged_df)\n",
    "\n",
    "# # Pivot the DataFrame to show Ages by City\n",
    "# pivot_df = df_read.pivot_table(index='City', values='Age', aggfunc='mean')\n",
    "# print(pivot_df)\n",
    "\n",
    "# # Save to a new Parquet file\n",
    "# df_read.to_parquet('manipulated_data.parquet', engine='pyarrow')\n",
    "\n",
    "# # Save to a CSV file\n",
    "# df_read.to_csv('manipulated_data.csv', index=False)\n",
    "\n",
    "# Add a new column\n",
    "df_read['IsAdult'] = df_read['Age'] >= 38\n",
    "\n",
    "# Filter rows\n",
    "filtered_df = df_read[df_read['IsAdult']]\n",
    "\n",
    "# Sort by Age\n",
    "sorted_df = filtered_df.sort_values(by='Age', ascending=False)\n",
    "\n",
    "# Save to a new Parquet file\n",
    "sorted_df.to_parquet('filtered_sorted_data.parquet', engine='pyarrow')\n",
    "\n",
    "print(\"Final DataFrame:\")\n",
    "print(sorted_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
